# llama-stack-runner
Tooling to run Llama Stack as a separate service

## Usage

```bash
export OPENAI_API_KEY="your_key"
```

```bash
uv run llama stack run run.yaml
```
